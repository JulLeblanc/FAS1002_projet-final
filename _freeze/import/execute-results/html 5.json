{
  "hash": "224cfdaf1f58d3d99caecc05ba99b47a",
  "result": {
    "markdown": "---\ntitle: \"Importation\"\ntitle-block-banner: true\ndescription: | \n  Cette page regroupe la première importation des données à l'état brute ainsi que les manipulation de bases.\n# à changer\ndate: \"2022-12-21\"\n# Modifier les détails que vous voulez\nauthor:\n  - name: \"Juliette Leblanc\"\n    # Votre site web perso ou github\n    url: https://github.com/JulLeblanc\n    # les champs d'affiliation sont optionnels, vous pouvez les\n    # comment out en ajoutant un # devant.\n    affiliation: FAS1002\n    affiliation-url: https://FAS1002.github.io/A22\n    # changer pour votre propre orcid id\n    # https://orcid.org/ pour vous inscrire.\n    # orcid: 0000-0000-0000-0000\n\n# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.\ncitation: true\n# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire\n# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n\nConsignes manquantes:\nPour l’importation des données, vous aurez à les télécharger de plusieurs sources (GitHub, Google Sheet ou Excel). Il y a plusieurs stratégies possibles, à vous de jouer!\n○ Cependant, vous devrez faire plus que de seulement importer les données. Puisque tout peut disparaître sur Internet ou être mis à jour sans préavis, vous devrez également télécharger les données. Par contre, il n’est pas optimal de procéder aux téléchargements à chaque fois que nous roulons le code. Les données brutes devront être téléchargées dans le dossier data/raw/ en respectant les conditions:\n■ Ainsi, pour les données qui proviennent de Our World in Data, vous devrez développer du code pour télécharger et sauvegarder les fichiers avec la date à laquelle le téléchargement a lieu. La fréquence du téléchargement devrait être quotidienne puisque les données sont mises à jour fréquemment. Pour vous simplifier la tâche, pensez à programmer également la suppression de l’ancien fichier une fois que le nouveau est téléchargé. En d’autres mots, ces données ne devraient être téléchargées qu’une seule fois par jour lorsque votre rapport est produit.\n■ Pour les données des autres sources, le principe est le même, mais la fréquence du téléchargement devra être mensuelle, donc à chaque mois seulement.\n■ ex: data/raw/owid\n\n\n#Importer les données\n\n## *Our World in Data*\n\nJ'utilise en premier la banque de données du *Co2 and Greenhouse Gaz Emissions*. Celle-ci sera mis à jour à tous les jours. Les données proviennent [d'ici](https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv).\n\n\n\n\n::: {.cell show_col_types='false' hash='import_cache/html/download co2_f978c59305e5276f4eea992d437a9b78'}\n\n```{.r .cell-code}\n#option cache=TRUE c'est si le code ne change pas, il ne devrait pas redownloader le fichier\n\nurl_owid <- \"https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\"\n\nbase_path <- path(\"data\", \"raw\") # pour que nimporte qui puisse download avec le chemin relatif\n\nfname_owid <- paste(today(), \"owid-co2-data.csv\", sep = \"_\") # name the file with today's date\n\nfpath_owid <- path(base_path, fname_owid) \n\ndata_owid <- download.file(url = url_owid, destfile = fpath_owid)\n\ndf_owid <- read_csv(fpath_owid,  show_col_types = FALSE)\n```\n:::\n\n\n## *Gapminder*\n\nPour la deuxième banque de données, je fais appel à celle produite par *Gapminder* qui se nomme *Life Expectancy at Birth*. Celle-ci seront re-téléchargé pour une mise à jour à tous les mois. Les données proviennent [d'ici](\"https://docs.google.com/spreadsheets/d/1RheSon1-q4vFc3AGyupVPH6ptEByE-VtnjOCselU0PE/edit#gid=176703676\")\n\n\n::: {.cell hash='import_cache/html/download lifeexpectancy_209651794c334a5aa1af6a8b17d03f13'}\n\n```{.r .cell-code}\nurl_gapminder <-  gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1RheSon1-q4vFc3AGyupVPH6ptEByE-VtnjOCselU0PE/edit#gid=176703676\")\n\nbase_path <- path(\"data\", \"raw\")\n\nfname_gap <- paste(today(), \"gapm.csv\", sep = \"_\")\n\nfpath_gap <- path(base_path, fname_gap)\n\nwrite_csv(x = url_gapminder, file = fpath_gap)\n\ndf_gapminder <- read_csv(fpath_gap, show_col_types = FALSE)\n```\n:::\n\n\n# Variable continent\n\nDans les deux banques de données que nous utilisons, j'ai créé une variable qui regroupe les différents pays en sous-groupe des 5 continents soit : l'Afrique, l'Amérique, l'Asie, l'Europe et l'Océanie. Ceci me permettra de faire des comparaisons plus large en me référant au continent et non au pays.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_owid <- df_owid |> \n    mutate(continent = countrycode(sourcevar = df_owid$country,\n                                   origin = \"country.name\",\n                                   destination = \"continent\"))\n\ndf_gapminder <- df_gapminder |> \n    mutate(continent = countrycode(sourcevar = df_gapminder$name,\n                                   origin = \"country.name\",\n                                   destination = \"continent\"))\n```\n:::\n\n\n# Recoder certaines variables\n\nDans les banques de données que nous utilisons, des variables qui regroupent le même type d'information n'ont pas nécessairement le même nom.\n\nNotamment, dans la banque de données \nr par uniformiser ceci, notamment en renommant les colonnes des pays pour `country`et pour l'année `year`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_gapminder <- df_gapminder |> \n    rename(country = name,\n           year = time)\n```\n:::\n\n\n\n# Joindre les banques de données\n\nLes deux banques de données contiennent une variable commune, soit la variable des pays. Nous allons donc procéder à combiner ces banques de données par leur variable commune, le pays.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# dat <- full_join(df_gapminder,\n#                  df_owid,\n#                  by = \"country\")\n```\n:::\n\n\n\n\n## Exporter\n\nMaintenant qu'une première manipulation des données a été fait, nous pouvons exporter celles-ci comme étant des données traitées dans le dossier `data/processed`.\n\nLes prochaines analyses auront comme point de départ les données traitées, donc qui ont été exportées dans le chemin relatif ci-dessus. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(df_owid,file = \"data/processed/df_owid.csv\")\n\nwrite_csv(df_gapminder, file = \"data/processed/df_gapminder.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}