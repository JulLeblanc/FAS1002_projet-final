{
  "hash": "28a428b7c3be794fbe3d6e50b6219c21",
  "result": {
    "markdown": "---\ntitle: \"Données\"\ntitle-block-banner: true\ndescription: | \n  Cette page regroupe la première importation des données à l'état brute ainsi que les manipulation de bases. \n# à changer\ndate: \"2022-12-21\"\n# Modifier les détails que vous voulez\nauthor:\n  - name: \"Juliette Leblanc\"\n    # Votre site web perso ou github\n    url: https://github.com/JulLeblanc\n    # les champs d'affiliation sont optionnels, vous pouvez les\n    # comment out en ajoutant un # devant.\n    affiliation: FAS1002\n    affiliation-url: https://FAS1002.github.io/A22\n    # changer pour votre propre orcid id\n    # https://orcid.org/ pour vous inscrire.\n    # orcid: 0000-0000-0000-0000\n\n# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.\ncitation: true\n# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire\n# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.\nbibliography: references.bib\n---\n\n::: {.cell}\n\n:::\n\n\n## Importer les données\n\n#### *Our World in Data* \n\nJ'utilise en premier la banque de données du *Co2 and Greenhouse Gaz Emissions*. Celle-ci sera mis à jour à tous les jours. \nLes données proviennent [d'ici](https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv).\n\nÀ retirer ou ajouter jsp encore:\nunlink(\"data/raw/*.csv\")\nunlink(\"data/raw/*.xlsx\")\n\n\n\n::: {.cell hash='import_cache/html/download_7cf52d3b828df85f53e2f6a81e215f5c'}\n\n```{.r .cell-code}\n#option cache=TRUE c'est si le code ne change pas, il ne devrait pas redownloader le fichier\n\nurl_owid <- \"https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\"\n\nbase_path <- path(\"data\", \"raw\") # pour que nimporte qui puisse download avec le chemin relatif\n\nfname_owid <- paste(today(), \"owid-co2-data.csv\", sep = \"_\") # name the file with today's date\n\nfpath_owid <- path(base_path, fname_owid) \n\ndata_owid <- download.file(url = url_owid, destfile = fpath_owid)\n\ndf_owid <- read_csv(fpath_owid)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 46523 Columns: 74\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): country, iso_code\ndbl (72): year, population, gdp, cement_co2, cement_co2_per_capita, co2, co2...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n#### *Gapminder*\n\nPour la deuxième banque de données, je fais appel à celle produite par *Gapminder* qui se nomme *Life Expectancy at Birth*. Celle-ci seront re-téléchargé pour une mise à jour à tous les mois.\nLes données proviennent [d'ici]()\n\n\n::: {.cell hash='import_cache/html/unnamed-chunk-2_9644cd250bea283a7930c435ede662fb'}\n\n```{.r .cell-code}\nurl_gapminder <- \"http://gapm.io/ilex\"\n\nbase_path <- path(\"data\", \"raw\")\n\nfname_gap <- paste(today(), \"gapm.csv\", sep = \"_\")\n\nfpath_gap <- path(base_path, fname_gap)\n\ndata <- download.file(url = url_gapminder, destfile = fpath_gap)\n\n# à changer pas le bon path\ndf_gapminder <- read_csv(\"data/raw/life_expectancy_years.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 195 Columns: 302\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): country\ndbl (301): 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n#### Créer une variable\n\nDans la banque de données de _Our World in Data_, nous avons créer une variable qui regroupe les différents pays en sous-groupe des 5 continents soit : l'Afrique, l'Amérique, l'Asie, l'Europe et l'Océanie.\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_owid <- df_owid |> \n    mutate(continent = countrycode(sourcevar = df_owid$country,\n                                   origin = \"country.name\",\n                                   destination = \"continent\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Africa, Africa (GCP), Antarctica, Asia, Asia (excl. China and India), Asia (GCP), Central America (GCP), Europe, Europe (excl. EU-27), Europe (excl. EU-28), Europe (GCP), European Union (27), European Union (27) (GCP), European Union (28), French Equatorial Africa (GCP), French West Africa (GCP), High-income countries, International transport, Kosovo, Leeward Islands (GCP), Low-income countries, Lower-middle-income countries, Micronesia (country), Middle East (GCP), Non-OECD (GCP), North America, North America (GCP), Oceania, Oceania (GCP), OECD (GCP), Ryukyu Islands (GCP), South America, South America (GCP), St. Kitts-Nevis-Anguilla (GCP), Timor, Upper-middle-income countries, World\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some strings were matched more than once, and therefore set to <NA> in the result: Asia (excl. China and India),Asia,Asia; St. Kitts-Nevis-Anguilla (GCP),Americas,Americas\n```\n:::\n:::\n\n\n#### Joindre les banques de données\n\nLes deux banques de données contiennent une variable commune, soit la variable des pays. Nous allons donc procéder à combiner ces banques de données par leur variable commune, le pays.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat <- full_join(df_gapminder,\n                 df_owid,\n                 by = \"country\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}